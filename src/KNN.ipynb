{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65550c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementasi dengan KNN\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "dataset1 = pd.read_csv('data_train.csv')\n",
    "dataset2 = pd.read_csv('data_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f290302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "class KNN:\n",
    "  def __init__(self, training_dataset, validation_dataset):\n",
    "    self.training_dataset = training_dataset\n",
    "    self.validation_dataset = validation_dataset\n",
    "    self.potential_k = []\n",
    "    self.k = 0\n",
    "\n",
    "    #variables for showing training result\n",
    "    self.potential_k_correct_counts = {}\n",
    "    self.validation_iteration = 0\n",
    "\n",
    "  def save_model(self, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(self, file)\n",
    "\n",
    "  @staticmethod\n",
    "  def load_model(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "  # training from dataset train and validation to find k\n",
    "  def train(self):\n",
    "    # Determining best K value\n",
    "    # K ditentukan dengan menentukan distance dari tiap data di dataset valid dengan data di dataset train, dengan k data dengan distance terdekat.\n",
    "    # Penghitungan k yang menghasilkan prediksi yang benar (atau sesuai dengan di dataset valid) akan dipetakan dengan berapa kali ia menghasilkan benar\n",
    "    # dan di akhir, k ditentukan dari k yang menghasilkan benar paling banyak\n",
    "\n",
    "    # Split dataset menjadi predictors and target\n",
    "    training_predictors = self.training_dataset.iloc[:, :-1]\n",
    "    test_predictors = self.validation_dataset.iloc[:, :-1]\n",
    "    training_target = self.training_dataset.iloc[:, -1]\n",
    "    validation_target = self.validation_dataset.iloc[:, -1]\n",
    "\n",
    "    # Fungsi untuk menghitung key yang menghasilkan prediksi yang benar\n",
    "    def correctKIncrement(key):\n",
    "      if key in self.potential_k_correct_counts:\n",
    "        self.potential_k_correct_counts[key] += 1\n",
    "      else:\n",
    "        self.potential_k_correct_counts[key] = 1\n",
    "\n",
    "    # Training dataset, ambil kolom target\n",
    "    df_euclidean_distance = self.training_dataset.copy()\n",
    "    df_euclidean_distance = df_euclidean_distance[['price_range']]\n",
    "\n",
    "    for i in range(len(self.validation_dataset)):\n",
    "      # Initiate variabel\n",
    "      k2distance_dict = {}\n",
    "      temporary_column_name = \"eu_dist_to_valid_row\"+str(i)\n",
    "\n",
    "      euclidean_distances = []\n",
    "      differences = test_predictors.iloc[i].values - training_predictors.values\n",
    "      distances = np.linalg.norm(differences, axis=1)\n",
    "      euclidean_distances = distances.tolist()\n",
    "      df_euclidean_distance[temporary_column_name] = euclidean_distances\n",
    "\n",
    "      # Cari K value dengan menghitung rata-rata dari k data dengan distance terdekat\n",
    "      for j in range(1,len(self.training_dataset)+1):\n",
    "        k2distance_dict[j] = df_euclidean_distance.sort_values(temporary_column_name)[\"price_range\"].head(j).mean()\n",
    "\n",
    "      # Proses fitness K dengan menghitung prediksi yang benar dan memasukkannya ke dalam map\n",
    "      for j in k2distance_dict:\n",
    "        if (k2distance_dict.get(j) == validation_target[i]):\n",
    "          correctKIncrement(j)\n",
    "        elif (validation_target[i]-0.5 <= k2distance_dict.get(j) < validation_target[i]+0.5 and 0 <= k2distance_dict.get(j) <= 3):\n",
    "          correctKIncrement(j)\n",
    "\n",
    "      # Drop kolom temporary\n",
    "      df_euclidean_distance = df_euclidean_distance.drop(columns=temporary_column_name)\n",
    "\n",
    "      # Setting nilai K\n",
    "      self.validation_iteration = i+1\n",
    "      self.potential_k = [key for key, value in self.potential_k_correct_counts.items() if value == max(self.potential_k_correct_counts.values())]\n",
    "      self.k = min(self.potential_k)  # K terbaik dengan K terkecil untuk mencegah overfitting\n",
    "\n",
    "  # Show training result\n",
    "  def showTrainingResult(self):\n",
    "    print(f\"K values with the most correct predictions are K = {self.potential_k}\")\n",
    "    correct_count = max(self.potential_k_correct_counts.values())\n",
    "    validation_count = self.validation_iteration\n",
    "    print(f\"With said K value(s) being correct {correct_count} times out of {validation_count} ({correct_count/validation_count})\")\n",
    "    print(f'According to sklearn.metrics, the validity score of the model with accuracy_score() is {accuracy_score(self.validation_dataset.iloc[:,-1].values, self.validate())}')\n",
    "\n",
    "  def validate(self):\n",
    "    valid_dataset = self.validation_dataset\n",
    "    preds, df = self.predict(valid_dataset)\n",
    "    return preds\n",
    "\n",
    "  # Prediksi dari dataset test\n",
    "  def predict(self, test_dataset):\n",
    "    # split datasets\n",
    "    training_predictors = self.training_dataset.iloc[:, :-1].copy()\n",
    "    training_target = self.training_dataset.iloc[:, -1].copy()\n",
    "    \n",
    "\n",
    "    # split test dataset\n",
    "    # splitting test dataset into columns in and not in training dataset\n",
    "    if (set(self.training_dataset.columns) != set(test_dataset.columns)):\n",
    "      processable_cols = set(self.training_dataset.columns) & set(test_dataset.columns)\n",
    "      test_dataset_processable = test_dataset[list(processable_cols)].copy()\n",
    "      # columns now match as needed\n",
    "      # aligning dataframe columns to match\n",
    "      test_dataset_processable = test_dataset_processable[training_predictors.columns]\n",
    "      test_dataset_complement = test_dataset[list(set(test_dataset.columns) - (processable_cols))]\n",
    "    else:\n",
    "      # splitting test dataset if they have target attribute at the end\n",
    "      # if (set(self.training_dataset.columns) - (set(test_dataset_processable.columns)) == set(self.training_dataset.columns[-1]) and self.training_dataset.columns[-1] == test_dataset.columns[-1]):\n",
    "      if (self.training_dataset.columns[-1] == test_dataset.columns[-1]):\n",
    "        test_dataset_processable = test_dataset.iloc[:,:-1]\n",
    "        # test_target = test_dataset_processable.iloc[:,-1].copy()\n",
    "      test_dataset_complement = pd.DataFrame() # both test and training dataset dont have different attributes\n",
    "\n",
    "    test_predictors = test_dataset_processable\n",
    "\n",
    "    # Inisiasi variabel\n",
    "    predicted_values = []\n",
    "    df_euclidean_distance = self.training_dataset.copy()\n",
    "    df_euclidean_distance = df_euclidean_distance[['price_range']]\n",
    "\n",
    "    for i in range(len(test_dataset)):\n",
    "      # Inisiasi variabel yang digunakan untuk setiap baris di dataset test\n",
    "      temporary_column_name = \"eu_dist_to_valid_row\"+str(i)\n",
    "\n",
    "      euclidean_distances = []\n",
    "      differences = test_predictors.iloc[i].values - training_predictors.values\n",
    "      distances = np.linalg.norm(differences, axis=1)\n",
    "      euclidean_distances = distances.tolist()\n",
    "      df_euclidean_distance[temporary_column_name] = euclidean_distances\n",
    "\n",
    "      # Hitung prediksi KNN dan masukkan ke dalam array\n",
    "      prediction = df_euclidean_distance.sort_values(temporary_column_name)[\"price_range\"].head(self.k).mean()\n",
    "\n",
    "      # putting statistical values to round categorial values (following dataset values)\n",
    "      # prediction = round(prediction) # python round() rounds 0.5 downward\n",
    "\n",
    "      # getting prediction float value\n",
    "      prediction_floatval = prediction - (prediction//1)\n",
    "      # if float value >= 0.5 then round them upward\n",
    "      if (prediction_floatval >= 0.5): \n",
    "        prediction //= 1\n",
    "        prediction += 1\n",
    "      else:\n",
    "      # if float value is <0.5 then round them downward\n",
    "        prediction //=1\n",
    "\n",
    "      predicted_values.append(prediction)\n",
    "\n",
    "      # Drop kolom temporary\n",
    "      df_euclidean_distance = df_euclidean_distance.drop(columns=temporary_column_name)\n",
    "\n",
    "    # attaching dataset prediction values to unprocessed columns\n",
    "    test_dataset_complement[training_target.name] = predicted_values\n",
    "    return predicted_values, test_dataset_complement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_Model = KNN(dataset1, dataset2)\n",
    "KNN_Model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing Training K Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_Model.showTrainingResult()\n",
    "# Putting K dictionary into a dataframe\n",
    "k_prediction_frequency = pd.DataFrame(list(KNN_Model.potential_k_correct_counts.items()), columns=[\"k\",\"frequency\"])\n",
    "display(k_prediction_frequency)\n",
    "print(\"Result of 50 best k values\")\n",
    "display(k_prediction_frequency.sort_values(\"frequency\", ascending=False).head(50))\n",
    "\n",
    "KNN_Model.save_model('knn_model.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading KNN from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_knn = KNN.load_model('knn_model.txt')\n",
    "\n",
    "loaded_knn.showTrainingResult()\n",
    "\n",
    "k_prediction_frequency = pd.DataFrame(list(loaded_knn.potential_k_correct_counts.items()), columns=[\"k\",\"frequency\"])\n",
    "display(k_prediction_frequency)\n",
    "print(\"Result of 50 best k values\")\n",
    "display(k_prediction_frequency.sort_values(\"frequency\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"test/test.csv\")\n",
    "submission_csv = pd.read_csv(\"test/submission.csv\")\n",
    "submission_values = submission_csv[\"price_range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, submission = loaded_knn.predict(test_dataset)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy:',accuracy_score(submission_values, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
